{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import expanduser\n",
    "import re, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from itertools import zip_longest\n",
    "from operator import itemgetter\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import jsonlines as jsonl\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_run = True\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(emb_path: str) -> dict:\n",
    "    \"\"\"load glove vectors\"\"\"\n",
    "    \n",
    "    embeddings_index={}\n",
    "    \n",
    "    with zipfile.ZipFile(expanduser(\"~\")+ emb_path +'glove.6B.zip', 'r') as f:\n",
    "        with f.open('glove.6B.100d.txt', 'r') as z:\n",
    "            for line in z:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float16')\n",
    "                embeddings_index[word] = coefs\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "def id_to_glove(dict_yelp: corpora.Dictionary, emb_path: str):\n",
    "    \n",
    "    \"\"\"converts local dictionary to embeddings from glove\"\"\"\n",
    "    \n",
    "    embeddings_index = load_embeddings(emb_path)\n",
    "    conversion_table = {}\n",
    "    \n",
    "    for word in dict_yelp.values():\n",
    "        if bytes(word, 'utf-8') in embeddings_index.keys():\n",
    "            conversion_table[dict_yelp.token2id[word]+1] = embeddings_index[bytes(word, 'utf-8')]\n",
    "        else:\n",
    "            conversion_table[dict_yelp.token2id[word]+1] = np.random.normal(0, .32, 100)\n",
    "            \n",
    "    embedding_matrix = np.vstack(\n",
    "        (\n",
    "            np.zeros(100), \n",
    "            list(conversion_table.values()), \n",
    "            np.random.randn(100)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "def convert_rating(rating):\n",
    "    \n",
    "    \"\"\"moving ratings from 0 to 1\"\"\"\n",
    "    \n",
    "    if rating in [4,5]:\n",
    "        return 1\n",
    "    elif rating in [1,2]:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def text_sequencer(dictionary, text, max_len=200):\n",
    "    \n",
    "    \"\"\"converts tokens to numeric representation by dictionary\"\"\"\n",
    "    \n",
    "    processed = np.zeros(200, dtype=int)\n",
    "    # in case the word is not in the dictionary because it was filtered out use this number to represent an out of set id \n",
    "    dict_final = len(dictionary.keys()) + 1\n",
    "    \n",
    "    for i, word in enumerate(text):        \n",
    "        if i >= max_len:\n",
    "            return processed\n",
    "        if word in dictionary.token2id.keys():\n",
    "            # the ids have an offset of 1 for this because 0 represents a padded value        \n",
    "            processed[i] = dictionary.token2id[word] + 1\n",
    "        else:\n",
    "            processed[i] = dict_final\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# regex tokenize, less accurate\n",
    "def tokenize(x): return re.findall('\\w+', x.lower())\n",
    "\n",
    "def load_data(path: str, fname: str, stop: int = None) -> list:\n",
    "    \"reads from zipped yelp data file\"\n",
    "    ls = []\n",
    "    with zipfile.ZipFile(path) as zfile:\n",
    "        print(zfile.namelist())\n",
    "        inf = zfile.open(fname)\n",
    "        with jsonl.Reader(inf) as file:\n",
    "            for i, line in enumerate(file):\n",
    "                line['text'] = tokenize(line.get('text'))\n",
    "                ls.append(line)\n",
    "                if stop and i == stop-1:\n",
    "                    break\n",
    "    return ls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CorpusData(Dataset):\n",
    "    \n",
    "    \"\"\"Dataset class required for pytorch to output items by index\"\"\"\n",
    "    \n",
    "    test_size = 0.25\n",
    "    def __init__(\n",
    "        self, \n",
    "        fpath: str, \n",
    "        fname: str, \n",
    "        stop: int = None, \n",
    "        data: str = 'data',\n",
    "        labels: str = 'target', \n",
    "        test_size=0.25\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fpath: str\n",
    "        self.fname: str\n",
    "        self.stop: int = None\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.dict_yelp: corpora.Dictionary = None\n",
    "        self.df: pd.DataFrame = self.parse_data(fpath, fname, stop)\n",
    "        self.test_size: float = test_size\n",
    "        self.tr_idx: list = None\n",
    "        self.val_idx: list = None\n",
    "        self.split_df()\n",
    "        \n",
    "    def parse_data(self, fpath, fname, stop):\n",
    "        \n",
    "        df = pd.DataFrame(load_data(fpath, fname, stop))\n",
    "        print('df loaded..')\n",
    "        self.dict_yelp = corpora.Dictionary(df.text)\n",
    "        self.dict_yelp.filter_extremes(no_below=10, no_above=.95, keep_n=30000)\n",
    "        print('dictionary created...')\n",
    "        df[self.data] = df.text.apply(lambda x: text_sequencer(self.dict_yelp, x))\n",
    "        df[self.labels] = df.stars.apply(convert_rating)\n",
    "        \n",
    "        return df.loc[df[self.labels].dropna()].reset_index(drop=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.__len__()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        return self.df[self.data][i], self.df[self.labels][i]\n",
    "            \n",
    "    def split_df(self):\n",
    "        \n",
    "        self.tr_idx, self.val_idx = train_test_split(self.df.index.values, test_size = self.test_size)\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.df.iloc[self.tr_idx]\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.df.iloc[self.val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "fpath = '../data/archive.zip'\n",
    "fname = 'yelp_academic_dataset_review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset_User_Agreement.pdf', 'yelp_academic_dataset_business.json', 'yelp_academic_dataset_checkin.json', 'yelp_academic_dataset_review.json', 'yelp_academic_dataset_tip.json', 'yelp_academic_dataset_user.json']\n",
      "df loaded..\n",
      "dictionary created...\n",
      "CPU times: user 1.95 s, sys: 32.2 ms, total: 1.98 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = CorpusData(\n",
    "    fpath=fpath, \n",
    "    fname=fname, \n",
    "    stop=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 78.1 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_matrix = id_to_glove(dataset.dict_yelp, '/projects/yelp_nlp/data/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_array(all_lens): \n",
    "    return np.unique(all_lens), np.bincount(all_lens), len(np.unique(all_lens)), len(np.bincount(all_lens))\n",
    "\n",
    "def resort_lens(idx, lens):\n",
    "    resorted_lenidx = np.array(sorted(zip(idx, lens), key=itemgetter(1), reverse=True))\n",
    "    return resorted_lenidx\n",
    "\n",
    "def resample_data(data, label, idx, lens):\n",
    "    \n",
    "        if isinstance(data, np.ndarray):\n",
    "            pass\n",
    "        else:\n",
    "            data= np.array(data)\n",
    "        assert len(data) == len(label)\n",
    "        sorted_ = resort_lens(idx, lens)\n",
    "        return data[sorted_[:,0]], label[sorted_[:,0]], sorted_[:,1]\n",
    "    \n",
    "#trainiter = iter(train_loader)\n",
    "\n",
    "def sort_lens(x, y, lens):\n",
    "    x=torch.stack(x,dim=1)\n",
    "    lens_, indices = lens.sort(descending=True)\n",
    "    x_, y_ = x[indices], y[indices]\n",
    "    return x_, y_, lens_\n",
    "\n",
    "def split(sorted_data, sorted_lab, all_lens, random_state=5):\n",
    "    \n",
    "    tr_idx, val_idx, tr_lens, val_lens = train_test_split(range(len(all_lens)), all_lens, \\\n",
    "                     test_size = 0.2, stratify=all_lens,\\\n",
    "                     random_state=random_state)\n",
    "    \n",
    "    train, train_y, tr_lens_ = resample_data(sorted_data, sorted_lab, tr_idx, tr_lens)\n",
    "    val, val_y, val_lens_ = resample_data(sorted_data, sorted_lab, val_idx, val_lens)\n",
    "    return {'train':[tr_idx, train, train_y, tr_lens_], 'val':[val_idx, val, val_y, val_lens_]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, bsize):\n",
    "    \n",
    "    count = int(len(y)/bsize)+1\n",
    "    def convert(lsls):\n",
    "        return torch.stack([torch.tensor(ls) for ls in lsls])\n",
    "    for i in range(count):\n",
    "        a,b,c = len(y[i*bsize:(i+1)*bsize]), x[i*bsize:(i+1)*bsize], y[i*bsize:(i+1)*bsize]\n",
    "        yield a, convert(b), torch.tensor(c) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    # weights are vocabsize x embedding length\n",
    "    def __init__(self, emb_weights, batch_size, input_len):\n",
    "    \n",
    "        super().__init__()\n",
    "        # vocab size in, hidden size out\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_layer = nn.Embedding(emb_weights.shape[0], emb_weights.shape[1])\n",
    "        self.emb_weights = emb_weights\n",
    "        # input of shape (seq_len, batch, input_size) https://pytorch.org/docs/stable/nn.html\n",
    "        self.lstm = nn.LSTM(input_len, input_len)\n",
    "        \n",
    "        \"\"\"Input: (N, *, \\text{in\\_features})(N,∗,in_features) where *∗ means any number of additional dimensions\n",
    "        Output: (N, *, \\text{out\\_features})(N,∗,out_features) where all but the last dimension are the same shape as the input.\"\"\"\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_len,1)\n",
    "        self.fc2 = nn.Linear(emb_weights.shape[1], 1)\n",
    "        \n",
    "\n",
    "    def load_weights(self):\n",
    "        self.embed_layer.load_state_dict({'weight': self.emb_weights})\n",
    "        return self\n",
    "    \n",
    "    def forward(self, inputs, p=0.2, verbose=False):\n",
    "        \n",
    "        \n",
    "        embeds = self.embed_layer(inputs)\n",
    "        \n",
    "        nn.Dropout2d(p=p, inplace=True)(embeds)\n",
    "        \n",
    "        if verbose:\n",
    "            print('embedding shape %s' % (embeds.shape,))\n",
    "        \n",
    "        out, (hidden, cell) = self.lstm(embeds.permute(0,2,1))\n",
    "        \n",
    "        if verbose:\n",
    "            print('lstm out shape %s' % (out.shape,))\n",
    "        \n",
    "        out = F.relu(self.fc1(out))\n",
    "        if verbose:\n",
    "            print('fc1 out shape %s' % (out.shape,))\n",
    "        \n",
    "        fout = self.fc2(out.view(1,-1,100))\n",
    "        if verbose:\n",
    "            print('final %s' % (fout.shape,))\n",
    "        #prob = torch.sigmoid(fout)\n",
    "        \n",
    "        return torch.sigmoid(\n",
    "            torch.squeeze(fout)\n",
    "        ) \n",
    "    \n",
    "class RNNpacked(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_weights, batch_size, input_len):\n",
    " \n",
    "        super().__init__()\n",
    "        \n",
    "        # vocab size in, hidden size out\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_layer = nn.Embedding(emb_weights.shape[0], emb_weights.shape[1])\n",
    "        self.emb_weights = emb_weights\n",
    "        self.dropout1 = nn.Dropout(p=0.5, inplace=True) \n",
    "        self.dropout3d1 = nn.Dropout3d(p=0.5, inplace=True)\n",
    "        self.dropout3d2 = nn.Dropout3d(p=0.5, inplace=True)\n",
    "        \n",
    "        # input of shape (seq_len, batch, input_size) https://pytorch.org/docs/stable/nn.html\n",
    "        self.lstm = nn.LSTM(emb_weights.shape[1], emb_weights.shape[1])\n",
    "        self.dropout2d1 = nn.Dropout2d(p=0.5, inplace=True)\n",
    "        self.dropout2d2 = nn.Dropout2d(p=0.5, inplace=True)\n",
    "        \n",
    "        \"\"\"Input: (N, *, \\text{in\\_features})(N,∗,in_features) where *∗ means any number of additional \n",
    "        dimensions Output: (N, *, \\text{out\\_features})(N,∗,out_features) where all but the last dimension \n",
    "        are the same shape as the input.\"\"\"\n",
    "        \n",
    "        self.fc1 = nn.Linear(emb_weights.shape[1], 1)\n",
    "        self.fc2 = nn.Linear(input_len,1)\n",
    "        \n",
    "    def load_weights(self):\n",
    "        self.embed_layer.load_state_dict({'weight': self.emb_weights})\n",
    "        return self\n",
    "    \n",
    "    def forward(self, inputs, input_lengths=None, verbose=False):\n",
    "        if verbose:\n",
    "            print('inputs', inputs.shape)\n",
    "            \n",
    "        #self.dropout1(inputs)\n",
    "        embeds = self.embed_layer(inputs)\n",
    "        if verbose:\n",
    "            print('embeds', embeds.shape)\n",
    "            print(embeds)\n",
    "        \n",
    "        #self.dropout3d1(embeds)\n",
    "        self.dropout2d1(embeds)\n",
    "        \n",
    "        if verbose:    \n",
    "            print(embeds)\n",
    "        packed = rnn.pack_padded_sequence(embeds, input_lengths, batch_first=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print('packed', packed[0].shape)\n",
    "        out, (hidden, cell) = self.lstm(packed)\n",
    "        unpacked, lengths = rnn.pad_packed_sequence(out, total_length=200, batch_first=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print('unpacked', unpacked.shape)\n",
    "        out = self.fc1(unpacked)\n",
    "        if verbose:\n",
    "            print('out', out.shape)\n",
    "        \n",
    "        self.dropout2d2(out)\n",
    "        #self.dropout3d2(out)\n",
    "        \n",
    "        fout = self.fc2(out.permute(0,2,1))\n",
    "        if verbose:\n",
    "            print('fout', fout.shape)\n",
    "        prob = F.sigmoid(\n",
    "            torch.squeeze(fout)\n",
    "        )\n",
    "        \n",
    "        return fout.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cuda'\n",
    "batch_size = 200\n",
    "input_len = 200\n",
    "emb_t = torch.from_numpy(embedding_matrix)\n",
    "emb = nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1])\n",
    "emb.load_state_dict({'weight': emb_t})\n",
    "model = RNN(emb_weights=emb_t, batch_size=batch_size, input_len=input_len)\n",
    "model.load_weights()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.7, 0.99), weight_decay=1e-5)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "# model_packed = RNNpacked(emb_weights=emb_t, batch_size=batch_size, input_len=input_len)\n",
    "# model_packed.load_weights()\n",
    "# model_packed.to(device)\n",
    "# optimizer = optim.Adam(model_packed.parameters(), lr=0.001)\n",
    "#torch.nn.utils.clip_grad_norm(mdl_sgd.parameters(),clip)\n",
    "\n",
    "def fit(model, loss_function, opitmizer, dataclass, batch_size, epochs, device, packed=False):\n",
    "    \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    epoch_count = 0\n",
    "    losses = []\n",
    "    train_loader = DataLoader(dataclass, batch_size=batch_size)\n",
    "\n",
    "    def train_epoch():\n",
    "        \n",
    "        nonlocal dataclass, train_loader, losses\n",
    "        \n",
    "        i=0\n",
    "        n=len(dataclass)\n",
    "        \n",
    "        for j, (sent, target) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "           \n",
    "            sent, labels = sent.long().to(device), target.float().to(device)\n",
    "            log_probs = model(sent)\n",
    "            #print(log_probs, labels)\n",
    "            loss = loss_function(log_probs, labels.to(device))\n",
    "            \n",
    "            # gets graident\n",
    "            loss.backward()\n",
    "            \n",
    "            # clips high gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.3, norm_type=2)\n",
    "            \n",
    "            # updates with new gradient\n",
    "            optimizer.step()\n",
    "            \n",
    "            i += len(labels)\n",
    "            #print(loss)\n",
    "            losses.append(loss.item())\n",
    "            if i % (batch_size*100) == 0:\n",
    "                print(f\"\"\"{i/n:.2f} of rows completed in {j+1} cycles, current loss at {np.mean(losses[-30:]):.4f}\"\"\" )\n",
    "\n",
    "    \n",
    "    print('fitting model...')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        train_epoch()\n",
    "        \n",
    "        epoch_count += 1\n",
    "        print(f'epoch {epoch_count} complete')\n",
    "    print(f'fit complete {time.time()-start:.0f} seconds passed')\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model...\n",
      "epoch 1 complete\n",
      "fit complete 1 seconds passed\n",
      "CPU times: user 983 ms, sys: 0 ns, total: 983 ms\n",
      "Wall time: 980 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import pdb; pdb.set_trace()\n",
    "losses = fit(model, loss_function, optimizer, \n",
    "                    dataset, batch_size, 1, device=device, \n",
    "                    packed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "for item in optimizer.param_groups:\n",
    "    print(item['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-de6c5f3362a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.xlim(0, 500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plt.ylim(0,.7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "_ = plt.plot(losses)\n",
    "# plt.xlim(0, 500)\n",
    "# plt.ylim(0,.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valcls = CorpusData(data=val, labels=val_y)\n",
    "#val_loader = DataLoader(valcls, batch_size=250)\n",
    "\n",
    "def eval_model(model, valcls, loss_function, batch_size):\n",
    "    \n",
    "    val_loader = DataLoader(valcls, batch_size=batch_size)\n",
    "    preds = []; targets = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "        for sent, target in val_loader:\n",
    "            #seqs, labels, lens_ = sort_lens(sent, target, lens)\n",
    "            #seqs = seqs.long().to(device)\n",
    "\n",
    "            res = model(sent.cuda())\n",
    "            \n",
    "            preds.append(res), targets.append(target)\n",
    "    \n",
    "    res = torch.cat(preds).cpu()\n",
    "    tru = torch.cat(targets).cpu()\n",
    "    \n",
    "    print(loss_function(res, tru.float()))    \n",
    "    \n",
    "\n",
    "    return res, tru\n",
    "\n",
    "preds, tru = eval_model(model, valcls, loss_function, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(true, preds, cutoff):\n",
    "    #preds = 1/(1+np.exp(-preds))\n",
    "    \n",
    "    res = np.greater(preds, np.array(cutoff))\n",
    "    recall = np.sum(res*true) / np.sum(true)\n",
    "    precision = np.sum(res*true) / np.sum(res)\n",
    "    return {'accuracy':round(np.mean(np.equal(true, res)), 4), 'precision': round(precision,4),\\\n",
    "            'recall': round(recall, 4), 'combined':round(precision*recall,4)}\n",
    "\n",
    "def get_reviewtext(row): \n",
    "    return ' '.join([dict_yelp[item-1] for item in traincls[row][0] if (item < 12589) and (item != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val, val_y, regression = False):\n",
    "    \n",
    "        \n",
    "    preds = model.predict(val)\n",
    "    #idx = np.random.randint(0, len(val_y), 5000)\n",
    "    pred_err = np.subtract(val_y.astype('float32'), preds.reshape(-1))\n",
    "    sns.distplot(pred_err)\n",
    "    plt.show()\n",
    "   \n",
    "    if regression:\n",
    "        rmse = np.sqrt(np.mean(pred_err**2))\n",
    "        print('rmse : %.4f' % rmse)\n",
    "    else:\n",
    "        cond_error = round((abs(pred_err) >= 0.5).sum()/len(pred_err), 4)\n",
    "        binary_cross_entropy = np.mean(\n",
    "                                        val_y * np.log(preds.reshape(-1)) + \\\n",
    "                                       (1-val_y) * np.log(1-preds.reshape(-1))\n",
    "        ) \n",
    "    \n",
    "        print('prob error is greater than 0.5 is %.4f' % cond_error)\n",
    "        print('binary cross entropy is %.4f' % binary_cross_entropy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
